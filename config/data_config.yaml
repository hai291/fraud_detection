# Data Configuration
data:
  # Dataset paths
  train_path: "dataset/processed/train.json"
  val_path: "dataset/processed/val.json"
  test_path: "dataset/processed/test.json"
  
  # Data preprocessing
  max_length: 512
  truncation: true
  padding: "max_length"
  
  # Data loading
  num_workers: 4
  prefetch_factor: 2
  
  # Data augmentation
  augmentation:
    enabled: false
    techniques:
      - "synonym_replacement"
      - "random_insertion"
      - "random_swap"
      - "random_deletion"
    probability: 0.1
  
  # Text processing
  tokenizer:
    name: "bert-base-uncased"
    cache_dir: "cache/tokenizer"
    do_lower_case: true
    
  # Data split ratios (if splitting is needed)
  split_ratios:
    train: 0.8
    val: 0.1
    test: 0.1
  
  # Sampling
  sampling:
    strategy: "random"  # random, balanced, stratified
    seed: 42
    
# Dataset specific parameters
dataset:
  name: "custom_dataset"
  task_type: "classification"  # classification, regression, generation
  label_column: "label"
  text_column: "text"
